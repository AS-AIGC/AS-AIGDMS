{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AS-AIGC/AS-AIGDMS/blob/main/colab_notebook_AS_AIGDMS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我們在這段程式碼中，主要是在安裝一些 Python 的套件。這些套件有助於我們處理各種任務，如下載 YouTube 影片、處理音訊檔案，甚至還有一些是來自 GitHub 的開發版本。我們通過 pip 工具（Python 的套件管理工具）來安裝這些套件。\n",
        "\n",
        "In this block of code, we're essentially installing some Python packages. These packages help us with various tasks like downloading YouTube videos, processing audio files, and even some are the development versions from GitHub. We're using pip, which is a package management tool in Python, to install these packages."
      ],
      "metadata": {
        "id": "Rh_lCEjHaq15"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3kGCg9OqFJ4"
      },
      "outputs": [],
      "source": [
        "# Install the whisper-timestamped library from GitHub\n",
        "!pip3 install git+https://github.com/linto-ai/whisper-timestamped\n",
        "\n",
        "# Install the development version of the pyannote-audio library\n",
        "!pip install -qq https://github.com/pyannote/pyannote-audio/archive/develop.zip\n",
        "\n",
        "# Install the Pytube library for downloading YouTube videos\n",
        "!pip install -q --upgrade pytube\n",
        "\n",
        "# Install the Pydub library for working with audio files\n",
        "!pip install -q --upgrade pydub\n",
        "\n",
        "# Install the pysrt library for handling subtitles\n",
        "!pip install pysrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ1ZyH7ZPdD-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from pytube import YouTube    # library for downloading YouTube videos\n",
        "from pydub import AudioSegment    # library for working with audio files\n",
        "import whisper_timestamped\n",
        "from pyannote.audio import Pipeline\n",
        "import pysrt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rtchp31KKj1q"
      },
      "outputs": [],
      "source": [
        "def download_Youtube_video_audio_file(url, output_directory, audio_filename):\n",
        "  print(f\"Download url: {url}\")\n",
        "  yt = YouTube(use_oauth=True, url=url)\n",
        "  # Get video's audio track\n",
        "  audio_stream = yt.streams.filter(only_audio=True).first()\n",
        "  audio_stream = yt.streams.get_audio_only()\n",
        "  \n",
        "  # Download it to Audio directory\n",
        "  audio_stream.download(output_path=output_directory, filename=audio_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PtKZsa_bO8qf"
      },
      "outputs": [],
      "source": [
        "def convert_audio_file_to_mp3_format(audio_filepath, export_path):\n",
        "  # Load the audio file into an AudioSegment object\n",
        "  print(\"Load the audio file\")\n",
        "  audio_file = AudioSegment.from_file(audio_filepath)\n",
        "\n",
        "  # Convert the audio file to MP3 format and save it to the mp3_format\n",
        "  print(\"Convert the audio file to MP3 format\\n\")\n",
        "  mp3_file = audio_file.export(export_path, format=\"mp3\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def slice_audio(audio_file, filename, offset):\n",
        "  # pydub does things in milliseconds\n",
        "  audio_length = audio_file.duration_seconds\n",
        "  minutes_duartion = int(audio_length // 60)\n",
        "  \n",
        "  one_minutes = 1 * 60 * 1000\n",
        "  # Set the start and end timestamp\n",
        "  start = offset * one_minutes\n",
        "  # The last part is less than one minute\n",
        "  end = audio_length if start == minutes_duartion else (offset+1) * one_minutes\n",
        "  sliced_audio = audio_file[start:end]\n",
        "  sliced_audio.export(filename, format=\"mp3\")"
      ],
      "metadata": {
        "id": "j8vgaAKfhx1V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_srt_files(audio_filename, languages):\n",
        "  # Create srt file for original caption\n",
        "  with open(f'{audio_filename}.srt', 'w') as fp:\n",
        "    pass\n",
        "  # Create srt files for multilingual subtitles\n",
        "  for language in languages:\n",
        "    with open(f'{audio_filename}_{language}.srt', \"w\") as fp:\n",
        "      pass"
      ],
      "metadata": {
        "id": "_RAWbHvxr_av"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def assign_speakers(caption_segments, diarization_result):\n",
        "  speakers = {}\n",
        "  for turn, track, speaker in diarization_result.itertracks(yield_label=True):\n",
        "    timestamp = {\"start\": turn.start, \"end\": turn.end}\n",
        "    if speakers.get(speaker):\n",
        "      speakers[speaker]['timestamp'].append(timestamp)\n",
        "    else:\n",
        "      speakers.update({speaker: {'timestamp': [timestamp], \"captions\": []}})\n",
        "\n",
        "  for segment in caption_segments:\n",
        "    speaker_offset = {}\n",
        "    for speaker, value in speakers.items():\n",
        "      if len(value['timestamp']) == 0:\n",
        "        continue\n",
        "      timestamp = value['timestamp'][0]\n",
        "      if timestamp['start'] > segment['end']:\n",
        "        continue\n",
        "      offset = abs(timestamp['start'] - segment['start'])\n",
        "      offset += abs(timestamp['end'] - segment['end'])\n",
        "      speaker_offset.update({speaker: offset})\n",
        "      \n",
        "    closest_speaker = sorted(speaker_offset.items(), key=lambda x:x[1])[0][0]\n",
        "    if len(speakers[closest_speaker]['timestamp']) > 0:\n",
        "      speakers[closest_speaker]['timestamp'][0]['start'] = segment['end']\n",
        "    for speaker, value in speakers.items():\n",
        "      timestamp = value['timestamp'][0]\n",
        "      if timestamp['end'] < segment['end']:\n",
        "        value['timestamp'].pop(0)\n",
        "    speakers[closest_speaker]['captions'].append(segment['text'])\n",
        "\n",
        "  speaker_captions = {}\n",
        "  for speaker, value in speakers.items():\n",
        "    speaker_captions.update({speaker: value['captions']})\n",
        "  return speaker_captions"
      ],
      "metadata": {
        "id": "RGW0akW6Vyzo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_url = \"https://www.youtube.com/watch?v=\"\n",
        "# The key is the Youtube video's id\n",
        "youtube_video = {\n",
        "    \"test1\": \"qeeA40t4MJY\"\n",
        "}\n",
        "languages = ['chinese (traditional)', 'english', 'japanese']\n",
        "access_token = \"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\"\n",
        "mp3_directory = './mp3/'\n",
        "audio_directory = \"./audio/\"\n",
        "srt_directory = \"./\"\n",
        "\n",
        "if not os.path.isdir(mp3_directory):\n",
        "  os.mkdir(mp3_directory)\n",
        "\n",
        "# Load the small model of whisper\n",
        "model = whisper_timestamped.load_model(\"small\")\n",
        "caption_segments = []\n",
        "for key, video_id in youtube_video.items():\n",
        "  audio_filename = \"audio_\" + key\n",
        "  # Download the audio file of the Youtube video\n",
        "  download_Youtube_video_audio_file(youtube_url+video_id, audio_directory, audio_filename)\n",
        "  \n",
        "  # Convert the audio file to MP3 format\n",
        "  audio_filepath = audio_directory + audio_filename\n",
        "  mp3_filepath = mp3_directory + audio_filename + \".mp3\"\n",
        "  convert_audio_file_to_mp3_format(audio_filepath, mp3_filepath)\n",
        "\n",
        "  # Load the mp3 file\n",
        "  mp3_file = AudioSegment.from_file(mp3_filepath, 'mp3')\n",
        "\n",
        "  # Create srt files\n",
        "  create_srt_files(audio_filename, languages)\n",
        "\n",
        "  # Transcribe the audio\n",
        "  mp3_duration_minutes = int(mp3_file.duration_seconds // 60)\n",
        "  seconds = round(mp3_file.duration_seconds - mp3_duration_minutes * 60, 2)\n",
        "  print(f\"Duration: {mp3_duration_minutes} minutes {seconds} seconds\\n\")\n",
        "  \n",
        "  # Chunk the audio per minute\n",
        "  for offset in range(mp3_duration_minutes + 1):\n",
        "    print(f\"Minute {offset}\")\n",
        "    filename = f\"{audio_filename}_{offset}_{offset+1}.mp3\"\n",
        "    # Slice the audio\n",
        "    slice_audio(mp3_file, filename, offset)   \n",
        "    \n",
        "    # Transcribe the video segment\n",
        "    print('Transcribe the chunked video')\n",
        "    result = model.transcribe(filename)\n",
        "    for segment in result['segments']:\n",
        "      caption_segments.append({'start': segment['start'] + offset * 60, \n",
        "                   'end': segment['end'] + offset * 60,\n",
        "                   'text': segment['text']})\n",
        "\n",
        "    # Write the original caption to a srt file\n",
        "    srt_writer = whisper_timestamped.utils.get_writer(\"srt\", srt_directory)\n",
        "    srt_writer(result, filename)\n",
        "\n",
        "    # Concatenate the caption\n",
        "    main_srt = f'{audio_filename}.srt'\n",
        "    sliced_part_srt = f\"{audio_filename}_{offset}_{offset+1}.srt\"\n",
        "    concatenate_srt_file(main_srt, sliced_part_srt, offset)\n",
        "\n",
        "    # Delete the sliced audio file and srt file.    \n",
        "    os.remove(filename)\n",
        "    os.remove(sliced_part_srt)\n",
        "    print('Done\\n')\n",
        "  \n",
        "  # Diarization\n",
        "  diarization_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization@2.1\",\n",
        "                            use_auth_token=access_token)\n",
        "  diarization_result = diarization_pipeline(mp3_filepath)\n",
        "  for turn, track, speaker in diarization_result.itertracks(yield_label=True):\n",
        "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s {speaker}, track:{track}\")\n",
        "  \n",
        "  # Record speakers' captions, respectively\n",
        "  speakers_caption = assign_speakers(caption_segments, diarization_result)\n",
        "  with open('./dirization_result.json', 'w') as fp: \n",
        "    json.dump(speakers_caption, fp, ensure_ascii=False, indent=2)"
      ],
      "metadata": {
        "id": "jC0-t5ATmCUX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}